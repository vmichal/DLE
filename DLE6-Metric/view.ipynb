{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Resize the notbook to full width, to fit more code and images \"\"\"\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\"\"\" some basic packages and settings to show images inline \"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "from lovely_numpy import lo\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\" automatically reload included modules (need to run import command to trigger reloading) \"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\" Controls for figure sizes to change \"\"\"\n",
    "plt.rcParams.update({'errorbar.capsize': 1})\n",
    "\n",
    "\"\"\" Lab support code \"\"\"\n",
    "from lab import test_set, load_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b8cbc",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2331c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for triplet model you will need to implement 'triplet_loss' and 'train_triplet' in lab.py\n",
    "# TODO: for smoothAP model you will need to implement 'smooth_AP_loss' and 'train_smooth_AP' in lab.py\n",
    "\n",
    "net = load_net('./models/net_class.pl') # load pretrained classification network\n",
    "# net = load_net('./models/net_triplet.pl') # load network trained with triplet loss\n",
    "# net = load_net('./models/net_smoothAP.pl') # load network trained with smoothAP loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4ea7e5",
   "metadata": {},
   "source": [
    "### Show nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff13c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# indices of query images\n",
    "query_idxs = np.random.choice(len(test_set), size=10, replace=False)\n",
    "\n",
    "# extract features for all test_samples\n",
    "from lab import get_features, distances\n",
    "loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=0)\n",
    "features, labels = get_features(net, loader, len(test_set))\n",
    "\n",
    "# TODO: implement 'distances' function in lab.py\n",
    "dists = distances(features, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0463ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nearest(test_set, labels, query_idxs, dists):\n",
    "    # show 50 nearest retrived images for every query in query_idxs\n",
    "    N = 50\n",
    "\n",
    "    f, axarr = plt.subplots(len(query_idxs), 1, gridspec_kw = {'wspace':0, 'hspace':0}, figsize=(16,4), dpi=200)\n",
    "\n",
    "    num_correct = np.zeros((len(query_idxs), ), dtype=np.int32)\n",
    "\n",
    "    for i, qidx in enumerate(query_idxs):\n",
    "        ax = axarr[i]\n",
    "        d = dists[qidx, :]\n",
    "        ds = torch.argsort(d)[:N+1]     # N+1 because the query image is retrieved as well\n",
    "        img = np.ones((28, 28*(N+1)+10, 3))\n",
    "        sid = 0\n",
    "        qimg = ((test_set[qidx][0] * 0.5) + 0.5).cpu().detach().numpy()\n",
    "        img[:, sid:sid+28, :] = np.stack((qimg, qimg, qimg), axis=-1)   # expand to three channels\n",
    "        qlab = labels[qidx]\n",
    "        sid += 28+10\n",
    "        for di in ds:\n",
    "            if di == qidx:  # skip the query image\n",
    "                continue\n",
    "            retrieved_img = ((test_set[di][0] * 0.5) + 0.5).cpu().detach().numpy()[0, :, :]\n",
    "            retrieved_img = np.stack((retrieved_img, retrieved_img, retrieved_img), axis=-1)\n",
    "            # start with a black frame\n",
    "            retrieved_img[:1, :, :] = 0\n",
    "            retrieved_img[-1:, :, :] = 0\n",
    "            retrieved_img[:, :1, :] = 0\n",
    "            retrieved_img[:, -1:, :] = 0\n",
    "            lab = labels[di]\n",
    "            if lab == qlab:     # correct -> green frame\n",
    "                retrieved_img[:1, :, 1] = 1\n",
    "                retrieved_img[-1:, :, 1] = 1\n",
    "                retrieved_img[:, :1, 1] = 1\n",
    "                retrieved_img[:, -1:, 1] = 1\n",
    "                num_correct[i] += 1\n",
    "            else:       # incorrect -> red frame\n",
    "                retrieved_img[:1, :, 0] = 1\n",
    "                retrieved_img[-1:, :, 0] = 1\n",
    "                retrieved_img[:, :1, 0] = 1\n",
    "                retrieved_img[:, -1:, 0] = 1\n",
    "            img[:, sid:sid+28] = retrieved_img\n",
    "            sid += 28\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = show_nearest(test_set, labels, query_idxs, dists)\n",
    "print(f'num_correct: {num_correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb521e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete 'evaluate_mAP' function\n",
    "from lab import evaluate_mAP\n",
    "mAP, mPrec, mRec = evaluate_mAP(net, test_set)\n",
    "print(f\"{mAP:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484bd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot Precision vs. Recall for all three models\n",
    "\n",
    "net = load_net('./models/net_class.pl') # load pretrained classification network\n",
    "mAP_clf, mPrec_clf, mRec_clf = evaluate_mAP(net, test_set)\n",
    "net = load_net('./models/net_triplet.pl') # load network trained with triplet loss\n",
    "mAP_triplet, mPrec_triplet, mRec_triplet = evaluate_mAP(net, test_set)\n",
    "net = load_net('./models/net_smoothAP.pl') # load network trained with smoothAP loss\n",
    "mAP_ap, mPrec_ap, mRec_ap = evaluate_mAP(net, test_set)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4), dpi=200)\n",
    "plt.plot(mRec_clf, mPrec_clf, label=\"cross-entropy\")\n",
    "plt.plot(mRec_triplet, mPrec_triplet, label=\"triplet\")\n",
    "plt.plot(mRec_ap, mPrec_ap, label=\"smoothAP\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
